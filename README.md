# AlignMyResume

AlignMyResume is a modern web application that helps job seekers align their resumes perfectly with specific job postings using AI-powered analysis. The application provides personalized recommendations and insights to improve resume effectiveness.

## Features

- ğŸ“ **Resume Analysis**: Upload your resume in DOCX or TXT format (max 2MB)
- ğŸ”— **URL Scraping**: Paste job posting URLs - AI automatically extracts content
- ğŸ” **Job Posting Analysis**: Compare your resume against specific job postings
- ğŸ¯ **Personalized Recommendations**: Get actionable, categorized suggestions
- ğŸ“Š **Detailed Scoring**: Receive scores across multiple categories
- ğŸ’¡ **AI-Powered Insights**: Market context, position analysis, and strategic advice
- âš¡ **Smart Caching**: 30-day Redis cache for faster repeat analyses (60-80% cost savings)
- ğŸ“± **Responsive Design**: Works seamlessly on desktop and mobile devices
- â™¿ **Accessibility**: WCAG 2.1 AA compliant with full keyboard navigation

## Tech Stack

### Frontend (Vercel)
- Next.js 15.3.3
- React 19
- TypeScript
- Tailwind CSS 4
- React Context API for state management

### Backend (GCP Cloud Run)
- **Scraping Service**: Node.js with Puppeteer + LangChain for intelligent content extraction
- **Analysis Service**: OpenAI GPT-4o-mini for resume analysis
- **Insights Service**: OpenAI GPT-4o-mini for strategic career insights
- **Cache Stats**: Redis monitoring and statistics

### Infrastructure
- **GCP Cloud Run**: Serverless container platform for backend services
- **Redis Memorystore**: 1GB cache for job postings and insights (30-day TTL)
- **Secret Manager**: Secure API key storage
- **VPC Network**: Private networking for Redis connectivity

### AI & Processing
- **OpenAI GPT-4o-mini**: Cost-optimized model for analysis and insights
- **LangChain**: Agentic AI framework for job posting extraction
- **Playwright**: Headless browser for web scraping
- **Mammoth.js**: DOCX file processing

## Prerequisites

### For Local Development
- Node.js 20+ (LTS recommended)
- npm or yarn
- OpenAI API key
- Redis (for local caching, optional)
  ```bash
  brew install redis  # macOS
  brew services start redis
  ```

### For GCP Deployment
- Google Cloud Platform account
- `gcloud` CLI configured
- Terraform (for infrastructure provisioning)
- Docker (for building container images)

## Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/align-my-resume.git
   cd align-my-resume
   ```

2. Install dependencies:
   ```bash
   npm install
   # or
   yarn install
   ```

3. Create a `.env.local` file in the root directory:
   ```bash
   # OpenAI API key for AI analysis
   OPENAI_API_KEY=your_openai_api_key_here

   # Redis connection (optional, for local caching)
   REDIS_URL=redis://localhost:6379

   # Toggle GCP backend (set to 'true' to use GCP services)
   NEXT_PUBLIC_USE_GCP=false
   ```

4. Start the development server:
   ```bash
   npm run dev
   # or
   yarn dev
   ```

5. Open [http://localhost:3000](http://localhost:3000) in your browser.

## Usage

1. **Choose Input Method**:
   - Toggle to "Use Job URL" to automatically scrape job postings
   - Or use "Paste Job Posting" to manually enter text

2. **Upload Resume**: Drop or select your resume (DOCX or TXT, max 2MB)

3. **Provide Job Details**:
   - For URL mode: Paste the job posting URL
   - For manual mode: Paste the full job description

4. **Analyze**: Click "Analyze Resume" and wait 10-30 seconds

5. **Review Results**:
   - **Job Analysis Tab**: View extracted requirements, responsibilities, and AI insights
   - **Recommendations Tab**: Get categorized, actionable improvement suggestions

6. **Apply Insights**: Use the recommendations to tailor your resume

## Project Structure

```
resume-tailor-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/              # Next.js app directory
â”‚   â”‚   â”œâ”€â”€ api/          # Vercel API routes (fallback)
â”‚   â”‚   â”œâ”€â”€ results/      # Results page
â”‚   â”‚   â””â”€â”€ page.tsx      # Home page
â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”œâ”€â”€ config/           # Configuration (endpoints, etc.)
â”‚   â”œâ”€â”€ context/          # React context providers
â”‚   â”œâ”€â”€ types/            # TypeScript type definitions
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ gcp/                  # GCP backend services
â”‚   â”œâ”€â”€ cloud-run/        # Cloud Run services
â”‚   â”‚   â””â”€â”€ scrape/       # Scraping service with Puppeteer
â”‚   â”œâ”€â”€ functions/        # Cloud Functions (Gen2)
â”‚   â”‚   â”œâ”€â”€ analyze/      # Resume analysis function
â”‚   â”‚   â”œâ”€â”€ insights/     # AI insights generation
â”‚   â”‚   â””â”€â”€ cache-stats/  # Cache monitoring
â”‚   â”œâ”€â”€ shared/           # Shared libraries
â”‚   â”‚   â””â”€â”€ lib/cache.js  # Redis client wrapper
â”‚   â””â”€â”€ terraform/        # Infrastructure as Code
â”œâ”€â”€ public/               # Static assets
â””â”€â”€ ...config files
```

## Architecture

### Hybrid Cloud Architecture
AlignMyResume uses a selective microservices approach, splitting workloads between Vercel and GCP:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    USER                                         â”‚
â”‚                            (Browser / Mobile)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ HTTPS
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           VERCEL (Frontend)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Next.js 15 App                                                          â”‚  â”‚
â”‚  â”‚  - React 19 UI Components                                                â”‚  â”‚
â”‚  â”‚  - Context API (State Management)                                        â”‚  â”‚
â”‚  â”‚  - Dynamic Endpoint Switching (NEXT_PUBLIC_USE_GCP)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚              â”‚
         â”‚ POST /scrape â”‚ POST         â”‚ POST         â”‚ GET
         â”‚              â”‚ /analyze     â”‚ /insights    â”‚ /cache-stats
         â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GOOGLE CLOUD PLATFORM (Backend)                            â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Scrape Serviceâ”‚  â”‚Analyze Serviceâ”‚  â”‚Insights Serviceâ”‚  â”‚ Cache Stats   â”‚  â”‚
â”‚  â”‚ (Cloud Run)   â”‚  â”‚(Cloud Functionâ”‚  â”‚(Cloud Functionâ”‚  â”‚(Cloud Functionâ”‚  â”‚
â”‚  â”‚               â”‚  â”‚     Gen2)     â”‚  â”‚     Gen2)     â”‚  â”‚     Gen2)     â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚â€¢ Puppeteer    â”‚  â”‚â€¢ OpenAI API   â”‚  â”‚â€¢ OpenAI API   â”‚  â”‚â€¢ Redis Client â”‚  â”‚
â”‚  â”‚â€¢ LangChain    â”‚  â”‚â€¢ GPT-4o-mini  â”‚  â”‚â€¢ GPT-4o-mini  â”‚  â”‚â€¢ Stats API    â”‚  â”‚
â”‚  â”‚â€¢ Redis Cache  â”‚  â”‚â€¢ Resume Parse â”‚  â”‚â€¢ Redis Cache  â”‚  â”‚               â”‚  â”‚
â”‚  â”‚â€¢ 50s Timeout  â”‚  â”‚â€¢ Job Analysis â”‚  â”‚â€¢ AI Insights  â”‚  â”‚               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚                  â”‚                  â”‚                  â”‚          â”‚
â”‚          â”‚                  â”‚                  â”‚                  â”‚          â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                      â”‚                                        â”‚
â”‚                         VPC Connector (alignmyresume-connector)               â”‚
â”‚                              10.9.0.0/28 (Private Network)                    â”‚
â”‚                                      â”‚                                        â”‚
â”‚                                      â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Redis Memorystore (1GB BASIC)                              â”‚ â”‚
â”‚  â”‚              10.0.0.3:6379 (Private IP)                                 â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Cache Keys:                                                            â”‚ â”‚
â”‚  â”‚  â€¢ job_posting:<url_hash>  â†’ Scraped job content (30-day TTL)          â”‚ â”‚
â”‚  â”‚  â€¢ insights:<analysis_hash> â†’ AI insights (30-day TTL)                 â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Benefits: 60-80% cost savings through deduplication                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Secret Manager                                       â”‚  â”‚
â”‚  â”‚  â€¢ openai-api-key (for all AI services)                                â”‚  â”‚
â”‚  â”‚  â€¢ redis-password (for Memorystore auth)                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

External APIs:
    â”‚
    â””â”€â”€â–º OpenAI GPT-4o-mini API (via HTTPS)
         - Resume analysis
         - Job posting extraction
         - Strategic insights generation

Request Flow Example (URL Scraping):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. User uploads resume + enters job URL
2. Frontend â†’ Scrape Service (check Redis cache by URL hash)
3. Cache MISS â†’ Puppeteer scrapes page â†’ LangChain extracts job posting â†’ Cache result
4. Frontend â†’ Analyze Service (resume + job posting â†’ OpenAI GPT-4o-mini)
5. Frontend â†’ Insights Service (check Redis cache by analysis hash)
6. Cache MISS â†’ Generate AI insights â†’ Cache result
7. Frontend displays: Job Analysis + Recommendations + AI Insights

Cost Optimization:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Redis caching: ~60-80% API cost reduction
â€¢ Cloud Run: Pay-per-request, auto-scaling (0-3 instances)
â€¢ GPT-4o-mini: Cost-optimized model vs GPT-4
â€¢ 30-day cache TTL: Balance freshness vs savings
â€¢ Projected monthly cost: ~$75-85 (under $100 budget)
```


**Frontend (Vercel)**:
- Next.js application with SSR and client-side routing
- Fast global CDN distribution
- Automatic deployments from `main` branch

**Backend (GCP Cloud Run)**:
- **Scrape Service**: Headless browser automation with Puppeteer for job posting extraction
- **Analysis Service**: GPT-4o-mini powered resume analysis against job requirements
- **Insights Service**: AI-generated strategic career insights and market context
- **Cache Stats**: Redis monitoring and statistics endpoint

**Caching Layer (Redis Memorystore)**:
- 1GB BASIC tier instance in us-east1
- 30-day TTL for job postings and insights
- Hash-based deduplication (SHA256 URL hashing)
- ~60-80% cost savings through intelligent caching

**Networking**:
- VPC Serverless Connector for private Redis access
- Secret Manager for secure API key storage
- Public HTTPS endpoints with CORS configuration

### Request Flow
1. User uploads resume and provides job URL/text
2. Frontend calls GCP scrape service (if URL mode)
3. Scrape service checks Redis cache â†’ scrapes if cache miss â†’ stores result
4. Frontend calls GCP analysis service with resume + job posting
5. Analysis service processes with OpenAI GPT-4o-mini
6. Frontend calls GCP insights service with job analysis data
7. Insights service checks cache â†’ generates if cache miss â†’ returns strategic insights
8. Results displayed in tabbed interface with recommendations and insights

## GCP Deployment

### Infrastructure Setup (One-time)
```bash
# Navigate to Terraform directory
cd gcp/terraform

# Initialize Terraform
terraform init

# Review planned changes
terraform plan -var="project_id=your-gcp-project" -var="region=us-east1"

# Apply infrastructure
terraform apply -var="project_id=your-gcp-project" -var="region=us-east1"

# Save outputs (Redis credentials, VPC connector info)
terraform output
```

### Deploy Backend Services
```bash
# Option 1: Deploy all services at once
cd gcp
chmod +x deploy.sh
./deploy.sh

# Option 2: Deploy individual services
cd gcp/cloud-run/scrape
gcloud run deploy scrape-service --source . --region us-east1

cd ../../functions/analyze
gcloud functions deploy analyze --gen2 --runtime nodejs20 --trigger-http --region us-east1

# Similar commands for insights and cache-stats functions
```

### Frontend Configuration
In Vercel dashboard, set environment variable:
```
NEXT_PUBLIC_USE_GCP=true
```

This toggles the frontend to call GCP backend services instead of Vercel API routes.

## Development

- `npm run dev` - Start development server
- `npm run build` - Build for production
- `npm run start` - Start production server
- `npm run lint` - Run ESLint

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Disclaimer

This application is currently in beta and under active development. Features may change and some functionality may be limited. The tool is designed for educational purposes and should be used as a guide rather than a definitive solution for resume alignment.

## Acknowledgments

- OpenAI for providing the GPT-4 API
- Next.js team for the amazing framework
- All contributors and users of the application
